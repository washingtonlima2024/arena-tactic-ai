

# Correcao: Transcri√ß√£o Travando em 27% - Concorr√™ncia do Whisper

## Problema

A transcri√ß√£o trava sempre em 27% porque o pipeline ass√≠ncrono usa `ThreadPoolExecutor(max_workers=4)` para transcrever partes em paralelo, mas o modelo Whisper (`_whisper_model`) √© um **singleton global compartilhado** entre todas as threads. O faster-whisper/ctranslate2 **n√£o √© thread-safe** - quando m√∫ltiplas threads tentam usar o mesmo modelo de GPU simultaneamente, ocorre um deadlock.

### Fluxo que Causa o Travamento

```text
_process_match_pipeline()
    |
    +-- ThreadPoolExecutor(max_workers=4)
    |       Thread 1 ‚Üí _transcribe_part_parallel ‚Üí ai_services.transcribe_audio_file ‚Üí _whisper_model.transcribe() üîí
    |       Thread 2 ‚Üí _transcribe_part_parallel ‚Üí ai_services.transcribe_audio_file ‚Üí _whisper_model.transcribe() üîí
    |       Thread 3 ‚Üí _transcribe_part_parallel ‚Üí ai_services.transcribe_audio_file ‚Üí _whisper_model.transcribe() üîí
    |       Thread 4 ‚Üí _transcribe_part_parallel ‚Üí ai_services.transcribe_audio_file ‚Üí _whisper_model.transcribe() üîí
    |                                                                                    ‚Üë DEADLOCK na GPU
    |
    +-- heartbeat_progress = 25 ‚Üí +2 = 27% ‚Üí TRAVA AQUI
```

O progresso chega a 27% (25 inicial + um tick de heartbeat de +2) e para, porque nenhuma thread consegue completar a transcri√ß√£o.

### O que os Scripts Alternativos Fazem Diferente

Os arquivos `ai_services_trans-2.py` e `server_trans-2.py` provavelmente funcionam melhor na transcri√ß√£o porque o fluxo de transcri√ß√£o dentro de `transcribe_large_video` √© sequencial (sem ThreadPoolExecutor), evitando o deadlock. Por√©m, eles "quebram outro processo" porque o pipeline ass√≠ncrono (`_process_match_pipeline`) continua usando a abordagem paralela.

## Solu√ß√£o

### Mudan√ßa Principal: Transcri√ß√£o Sequencial (n√£o paralela)

Alterar o pipeline ass√≠ncrono para processar as partes **sequencialmente** em vez de em paralelo, j√° que o Whisper n√£o suporta concorr√™ncia.

### Arquivo: `video-processor/server.py`

**Mudan√ßa 1** - Linhas 9015-9089: Substituir `ThreadPoolExecutor` por loop sequencial com progresso real

Remover o bloco inteiro do ThreadPoolExecutor e substituir por:

```python
                # Process parts SEQUENTIALLY (Whisper is NOT thread-safe)
                for idx, item in enumerate(all_parts_flat):
                    half_type_part = item['halfType']
                    part_info = item['partInfo']
                    minute_offset = item['minuteOffset']
                    
                    # Update part status to "transcribing"
                    for ps in parts_status:
                        if ps['halfType'] == half_type_part and ps['part'] == part_info['part']:
                            ps['status'] = 'transcribing'
                            ps['progress'] = 10
                            break
                    
                    progress = 20 + int(((idx) / len(all_parts_flat)) * 60)
                    _update_async_job(job_id, 'transcribing', progress, 
                                    f'Transcrevendo parte {idx + 1}/{len(all_parts_flat)}{gpu_info}...',
                                    'transcribing', completed_parts, total_parts, parts_status)
                    
                    result = _transcribe_part_parallel(part_info, half_type_part, match_id, minute_offset)
                    completed_parts += 1
                    
                    # Update part status
                    for ps in parts_status:
                        if ps['halfType'] == half_type_part and ps['part'] == part_info['part']:
                            ps['status'] = 'done' if result['success'] else 'error'
                            ps['progress'] = 100
                            if not result['success']:
                                ps['message'] = result.get('error', '')[:100]
                            break
                    
                    progress = 20 + int((completed_parts / len(all_parts_flat)) * 60)
                    
                    if result['success']:
                        transcription_results[half_type_part].append(result)
                        print(f"[ASYNC-PIPELINE] ‚úì Transcribed {half_type_part} part {result['part']}: {len(result['text'])} chars")
                        _update_async_job(job_id, 'transcribing', progress, 
                                        f'Parte {completed_parts}/{len(all_parts_flat)} transcrita',
                                        'transcribing', completed_parts, total_parts, parts_status)
                    else:
                        print(f"[ASYNC-PIPELINE] ‚úó Failed {half_type_part} part: {result.get('error')}")
                        _update_async_job(job_id, 'transcribing', progress, 
                                        f'Parte {completed_parts}/{len(all_parts_flat)} (erro)',
                                        'transcribing', completed_parts, total_parts, parts_status)
```

**Mudan√ßa 2** - Adicionar mutex no `_transcribe_with_local_whisper` (ai_services.py) como seguran√ßa extra

No topo do arquivo (perto da linha 2030), adicionar:

```python
import threading
_whisper_lock = threading.Lock()
```

E na fun√ß√£o `_transcribe_with_local_whisper` (linha ~2952), envolver a chamada do modelo com o lock:

```python
# Na fun√ß√£o _transcribe_single_file:
with _whisper_lock:
    segments_gen, info = _whisper_model.transcribe(...)
    # ... processar segments DENTRO do lock ...

# Na fun√ß√£o _transcribe_chunked, dentro do loop de chunks:
with _whisper_lock:
    segments_gen, info = _whisper_model.transcribe(...)
    # ... processar chunk DENTRO do lock ...
```

### Arquivo: `video-processor/ai_services.py`

**Mudan√ßa 3** - Adicionar lock global para o modelo Whisper

Adicionar na se√ß√£o de inicializa√ß√£o (~linha 2030):

```python
import threading
_whisper_lock = threading.Lock()
```

**Mudan√ßa 4** - Proteger `_transcribe_single_file` com lock (linha 3019):

```python
def _transcribe_single_file(audio_path: str, match_id: str = None) -> Dict[str, Any]:
    global _whisper_model
    
    print(f"[LocalWhisper] Transcrevendo arquivo √∫nico...")
    
    with _whisper_lock:
        segments_gen, info = _whisper_model.transcribe(
            audio_path, 
            language="pt",
            beam_size=5,
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=500)
        )
        
        # IMPORTANTE: Consumir o generator DENTRO do lock
        srt_lines = []
        full_text = []
        segments_list = []
        
        for i, seg in enumerate(segments_gen, 1):
            start_str = _format_srt_time(seg.start)
            end_str = _format_srt_time(seg.end)
            text = seg.text.strip()
            
            if text:
                srt_lines.append(f"{i}\n{start_str} --> {end_str}\n{text}\n")
                full_text.append(text)
                segments_list.append({
                    'start': seg.start,
                    'end': seg.end,
                    'text': text
                })
    
    # Resto do processamento fora do lock...
```

**Mudan√ßa 5** - Proteger itera√ß√£o do chunk na `_transcribe_chunked` (linha 3130):

```python
# Dentro do loop de retry de cada chunk:
with _whisper_lock:
    segments_gen, info = _whisper_model.transcribe(
        chunk_path,
        language="pt",
        beam_size=5,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500)
    )
    
    chunk_text = []
    for seg in segments_gen:
        text = seg.text.strip()
        if text:
            adjusted_start = start_time + seg.start
            adjusted_end = start_time + seg.end
            all_segments.append({...})
            chunk_text.append(text)
```

**Mudan√ßa 6** - Proteger `transcribe_upload_segments` (linha 3348):

```python
# Dentro do loop de retry:
with _whisper_lock:
    segments_gen, info = _whisper_model.transcribe(
        segment_path,
        language="pt",
        beam_size=5,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500)
    )
    
    texts = []
    for seg_result in segments_gen:
        text = seg_result.text.strip()
        if text:
            texts.append(text)
```

## Resumo das Altera√ß√µes

| Arquivo | Linha | Mudan√ßa |
|---|---|---|
| server.py | 9015-9089 | Substituir ThreadPoolExecutor por loop sequencial com progresso real |
| ai_services.py | ~2030 | Adicionar `_whisper_lock = threading.Lock()` |
| ai_services.py | 3019-3068 | Proteger `_transcribe_single_file` com `_whisper_lock` |
| ai_services.py | 3128-3167 | Proteger loop de chunks em `_transcribe_chunked` com `_whisper_lock` |
| ai_services.py | 3346-3363 | Proteger `transcribe_upload_segments` com `_whisper_lock` |

## Por que Sequencial e N√£o Paralelo?

O faster-whisper/ctranslate2 usa a GPU como recurso exclusivo. Mesmo com um mutex, executar 4 threads que ficam esperando o lock seria equivalente a execu√ß√£o sequencial mas com overhead de threading. A solu√ß√£o mais limpa √©:

1. **Loop sequencial** no pipeline (server.py) - elimina contention
2. **Mutex como seguran√ßa** (ai_services.py) - protege chamadas de outros pontos do sistema que possam chamar o Whisper simultaneamente

O progresso agora ser√° real: cada parte conclu√≠da avan√ßa proporcionalmente de 20% a 80%.

**Nota**: Todas as mudan√ßas s√£o no servidor local (`video-processor/`). Ap√≥s aplicar, reiniciar com `pm2 restart arena-backend`.
